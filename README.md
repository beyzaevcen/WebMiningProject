# Web Mining Project

## Project Overview
This project involves web mining from the website [asyafanatiklerim.com](http://asyafanatiklerim.com). The data extracted from the website was processed and analyzed using various Python libraries. The key steps involved in this project are web scraping, data cleaning and manipulation, data visualization, and predictive modeling.

## Tools and Libraries Used

1. **Scrapy**: Used for web scraping to extract data from the website.
2. **Pandas**: Utilized for data manipulation and cleaning.
3. **NumPy**: Assisted in numerical operations and handling arrays.
4. **Matplotlib**: Used for data visualization.
5. **Seaborn**: Also used for data visualization to create more advanced plots.
6. **Scikit-learn**: Employed for building and training the predictive model.
7. **Linear Regression**: Used as the predictive model for our analysis.

## Steps and Workflow

### 1. Web Scraping with Scrapy
We utilized the Scrapy library to scrape data from the website. The spider was configured to extract relevant data fields which were then saved in a structured format for further analysis.

### 2. Data Manipulation with Pandas and NumPy
After extracting the data, we performed various data cleaning and manipulation tasks using Pandas and NumPy. This included handling missing values, data transformation, and preparation for visualization and analysis.

### 3. Data Visualization with Matplotlib and Seaborn
For better understanding and insight into the data, we used Matplotlib and Seaborn libraries to create various visualizations such as:
- Bar charts
- Line graphs
- Histograms
- Scatter plots

These visualizations helped in identifying trends and patterns within the data.

### 4. Predictive Modeling with Scikit-learn
Once the data was cleaned and visualized, we prepared it for predictive modeling. Using Scikit-learn, we applied a linear regression model to make predictions based on the data. The model was trained and tested to evaluate its performance.

## How to Run the Project

1. **Set up the environment**: Ensure you have Python installed along with the required libraries. You can install the necessary libraries using:
   ```bash
   pip install scrapy pandas numpy matplotlib seaborn scikit-learn
2. **Run the Scrapy Spider**: Execute the Scrapy spider to scrape the data from the website:
   ```bash
   scrapy crawl <your_spider_name>
3. **Data Cleaning and Manipulation**: Use the provided Python scripts to clean and manipulate the data using Pandas and NumPy.

4. **Data Visualization:**: Generate visualizations by running the visualization scripts.

5. **Predictive Modeling: **:  Train and test the linear regression model using Scikit-learn as per the provided scripts.

### Conclusion
This project showcases the process of web scraping, data cleaning, visualization, and predictive modeling. The tools and techniques used are essential for any data analysis project, providing insights and making data-driven predictions.

For any questions or further assistance, feel free to reach out. Happy coding!   

### Team:
-Nermin Beyzanur Evcen

-Fatmatüzzehra Öztürk
  
